{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1GqTjeV47m4B"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# Instantiates the device to be used as GPU/CPU based on availability\n",
    "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KpuvHS0mxwCd"
   },
   "source": [
    "## Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYrAa5laSptM"
   },
   "source": [
    "### Alphabets Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "colab_type": "code",
    "id": "-a04ZKx7Sh-J",
    "outputId": "03e15a7f-e461-45bc-cd04-f9228c406fa2"
   },
   "outputs": [],
   "source": [
    "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "pad_char = '-PAD-'\n",
    "\n",
    "eng_alpha2index = {pad_char: 0}\n",
    "for index, alpha in enumerate(eng_alphabets):\n",
    "    eng_alpha2index[alpha] = index+1\n",
    "\n",
    "print(eng_alpha2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "colab_type": "code",
    "id": "cPSZsy1kXd9w",
    "outputId": "24b9a7a8-d16a-4480-a78e-1af28eec650b"
   },
   "outputs": [],
   "source": [
    "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
    "\n",
    "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
    "hindi_alphabet_size = len(hindi_alphabets)\n",
    "\n",
    "hindi_alpha2index = {pad_char: 0}\n",
    "for index, alpha in enumerate(hindi_alphabets):\n",
    "    hindi_alpha2index[alpha] = index+1\n",
    "\n",
    "print(hindi_alpha2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSw1SMZmx9A3"
   },
   "source": [
    "### Helper functions for data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OcS6ByndOxrC"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
    "\n",
    "# Remove all English non-letters\n",
    "def cleanEnglishVocab(line):\n",
    "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
    "    line = non_eng_letters_regex.sub('', line)\n",
    "    return line.split()\n",
    "\n",
    "# Remove all Hindi non-letters\n",
    "def cleanHindiVocab(line):\n",
    "    line = line.replace('-', ' ').replace(',', ' ')\n",
    "    cleaned_line = ''\n",
    "    for char in line:\n",
    "        if char in hindi_alpha2index or char == ' ':\n",
    "            cleaned_line += char\n",
    "    return cleaned_line.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ob3F9Dh4PChB"
   },
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KGSeoMGg0FTy"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "class TransliterationDataLoader(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
    "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
    "        random.shuffle(self.shuffle_indices)\n",
    "        self.shuffle_start_index = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.eng_words)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.eng_words[idx], self.hindi_words[idx]\n",
    "    \n",
    "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
    "        transliterationCorpus = ET.parse(filename).getroot()\n",
    "        lang1_words = []\n",
    "        lang2_words = []\n",
    "\n",
    "        for line in transliterationCorpus:\n",
    "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
    "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
    "\n",
    "            # Skip noisy data\n",
    "            if len(wordlist1) != len(wordlist2):\n",
    "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
    "                continue\n",
    "\n",
    "            for word in wordlist1:\n",
    "                lang1_words.append(word)\n",
    "            for word in wordlist2:\n",
    "                lang2_words.append(word)\n",
    "\n",
    "        return lang1_words, lang2_words\n",
    "    \n",
    "    def get_random_sample(self):\n",
    "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
    "    \n",
    "    def get_batch_from_array(self, batch_size, array):\n",
    "        end = self.shuffle_start_index + batch_size\n",
    "        batch = []\n",
    "        if end >= len(self.eng_words):\n",
    "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
    "            end = len(self.eng_words)\n",
    "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
    "    \n",
    "    def get_batch(self, batch_size, postprocess = True):\n",
    "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
    "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
    "        self.shuffle_start_index += batch_size + 1\n",
    "        \n",
    "        # Reshuffle if 1 epoch is complete\n",
    "        if self.shuffle_start_index >= len(self.eng_words):\n",
    "            random.shuffle(self.shuffle_indices)\n",
    "            self.shuffle_start_index = 0\n",
    "            \n",
    "        return eng_batch, hindi_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "-FCCi-SerZS-",
    "outputId": "f8cceb21-881e-4bf4-aa32-e40795411d88"
   },
   "outputs": [],
   "source": [
    "train_data = TransliterationDataLoader('NEWS2012-Training-EnHi-13937.xml')\n",
    "test_data = TransliterationDataLoader('NEWS2012-Ref-EnHi-1000.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7l-iaCVdx5Ez"
   },
   "source": [
    "### Basic Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "IjY06ghEx76b",
    "outputId": "279948f9-59ec-477a-fd44-8ddf8c96f368"
   },
   "outputs": [],
   "source": [
    "print(\"Train Set Size:\\t\", len(train_data))\n",
    "print(\"Test Set Size:\\t\", len(test_data))\n",
    "\n",
    "print('\\nSample data from train-set:')\n",
    "for i in range(10):\n",
    "    eng, hindi = train_data.get_random_sample()\n",
    "    print(eng + ' - ' + hindi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KpDP1_KYZIkv"
   },
   "source": [
    "### Encoding the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JE3at5C7Sy5F"
   },
   "outputs": [],
   "source": [
    "def word_rep(word, letter2index, device = 'cpu'):\n",
    "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
    "    for letter_index, letter in enumerate(word):\n",
    "        pos = letter2index[letter]\n",
    "        rep[letter_index][0][pos] = 1\n",
    "    pad_pos = letter2index[pad_char]\n",
    "    rep[letter_index+1][0][pad_pos] = 1\n",
    "    return rep\n",
    "\n",
    "def gt_rep(word, letter2index, device = 'cpu'):\n",
    "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
    "    for letter_index, letter in enumerate(word):\n",
    "        pos = letter2index[letter]\n",
    "        gt_rep[letter_index][0] = pos\n",
    "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
    "    return gt_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "-yE3jToOrfzP",
    "outputId": "f06ed7e4-97bb-4780-cb2f-1327226a7e64"
   },
   "outputs": [],
   "source": [
    "eng, hindi = train_data.get_random_sample()\n",
    "eng_rep = word_rep(eng, eng_alpha2index)\n",
    "print(eng, eng_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "uMcDjIberhc3",
    "outputId": "30270e8a-733a-432e-8992-34330ca44e04"
   },
   "outputs": [],
   "source": [
    "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
    "print(hindi, hindi_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GrC3tSnm4rUk"
   },
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D4OgdZ_DVVC5"
   },
   "source": [
    "### Encoder-Decoder (using GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6w8ffT3w4lkK"
   },
   "outputs": [],
   "source": [
    "MAX_OUTPUT_CHARS = 30\n",
    "class Transliteration_EncoderDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
    "        super(Transliteration_EncoderDecoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
    "        self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
    "        \n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
    "        \n",
    "        # encoder\n",
    "        out, hidden = self.encoder_rnn_cell(input)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('Encoder input', input.shape)\n",
    "            print('Encoder output', out.shape)\n",
    "            print('Encoder hidden', hidden.shape)\n",
    "        \n",
    "        # decoder\n",
    "        decoder_state = hidden\n",
    "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
    "        outputs = []\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('Decoder state', decoder_state.shape)\n",
    "            print('Decoder input', decoder_input.shape)\n",
    "        \n",
    "        for i in range(max_output_chars):\n",
    "            \n",
    "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('Decoder intermediate output', out.shape)\n",
    "            \n",
    "            out = self.h2o(decoder_state)\n",
    "            out = self.softmax(out)\n",
    "            outputs.append(out.view(1, -1))\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('Decoder output', out.shape)\n",
    "                self.verbose = False\n",
    "            \n",
    "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
    "            if not ground_truth is None:\n",
    "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
    "            one_hot = torch.FloatTensor(out.shape).to(device)\n",
    "            one_hot.zero_()\n",
    "            one_hot.scatter_(2, max_idx, 1)\n",
    "            \n",
    "            decoder_input = one_hot.detach()\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cra9toTiOoPm"
   },
   "outputs": [],
   "source": [
    "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model,word,max_output_chars=MAX_OUTPUT_CHARS):\n",
    "    word_tensor=word_rep(word,eng_alpha2index)\n",
    "    outputs=model(word_tensor,max_output_chars=MAX_OUTPUT_CHARS)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "v4zaJq2pOrM8",
    "outputId": "8f63335b-fa7d-401f-d4db-872dc20c508d"
   },
   "outputs": [],
   "source": [
    "out = infer(net, 'INDIA',30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "colab_type": "code",
    "id": "1_pdzBmQOsjO",
    "outputId": "b6fb8423-1f01-4f3c-f1b9-f5dd9a8fb752"
   },
   "outputs": [],
   "source": [
    "print(len(out))\n",
    "for i in range(len(out)):\n",
    "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NEg49N9e7oTY"
   },
   "source": [
    "### Encoder-Decoder with Attention \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8z-1QDAz8F_d"
   },
   "outputs": [],
   "source": [
    "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
    "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
    "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
    "        \n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size, 1)\n",
    "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
    "        \n",
    "        # encoder\n",
    "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
    "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('Encoder output', encoder_outputs.shape)\n",
    "        \n",
    "        # decoder\n",
    "        decoder_state = hidden\n",
    "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
    "        \n",
    "        outputs = []\n",
    "        U = self.U(encoder_outputs)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('Decoder state', decoder_state.shape)\n",
    "            print('Decoder intermediate input', decoder_input.shape)\n",
    "            print('U * Encoder output', U.shape)\n",
    "        \n",
    "        for i in range(max_output_chars):\n",
    "            \n",
    "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
    "            V = self.attn(torch.tanh(U + W))\n",
    "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
    "            \n",
    "            if self.verbose:\n",
    "                print('W * Decoder state', W.shape)\n",
    "                print('V', V.shape)\n",
    "                print('Attn', attn_weights.shape)\n",
    "            \n",
    "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "            \n",
    "            embedding = self.out2hidden(decoder_input)\n",
    "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('Attn LC', attn_applied.shape)\n",
    "                print('Decoder input', decoder_input.shape)\n",
    "                \n",
    "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('Decoder intermediate output', out.shape)\n",
    "                \n",
    "            out = self.h2o(decoder_state)\n",
    "            out = self.softmax(out)\n",
    "            outputs.append(out.view(1, -1))\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('Decoder output', out.shape)\n",
    "                self.verbose = False\n",
    "            \n",
    "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
    "            if not ground_truth is None:\n",
    "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
    "            one_hot = torch.zeros(out.shape, device=device)\n",
    "            one_hot.scatter_(2, max_idx, 1) \n",
    "            \n",
    "            decoder_input = one_hot.detach()\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMD3zjdJO0Oj"
   },
   "outputs": [],
   "source": [
    "net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "YoiQwbntO5UH",
    "outputId": "30e5ee26-fe66-426b-e2b6-5385c6c723f4"
   },
   "outputs": [],
   "source": [
    "out = infer(net_attn, 'INDIA', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "colab_type": "code",
    "id": "K9WSPgzlO6k8",
    "outputId": "55e23d81-96e5-456d-eb0b-eb470bfd3531"
   },
   "outputs": [],
   "source": [
    "print(len(out))\n",
    "for i in range(len(out)):\n",
    "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cyE2tSnmAW6x"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H893cimDtTUE"
   },
   "source": [
    "### Core Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m804jsH7AXSV"
   },
   "outputs": [],
   "source": [
    "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
    "    \n",
    "    net.train().to(device)\n",
    "    opt.zero_grad()\n",
    "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        input = word_rep(eng_batch[i], eng_alpha2index, device)\n",
    "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
    "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
    "        \n",
    "        for index, output in enumerate(outputs):\n",
    "            loss = criterion(output, gt[index]) / batch_size\n",
    "            loss.backward(retain_graph = True)\n",
    "            total_loss += loss\n",
    "        \n",
    "    opt.step()\n",
    "    return total_loss/batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-eZaBxstWz9"
   },
   "source": [
    "### Training Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rjto129ssrpr"
   },
   "outputs": [],
   "source": [
    "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
    "    \n",
    "    net = net.to(device)\n",
    "    criterion = nn.NLLLoss(ignore_index = -1)\n",
    "    opt = optim.Adam(net.parameters(), lr=lr)\n",
    "    teacher_force_upto = n_batches//3\n",
    "    \n",
    "    loss_arr = np.zeros(n_batches + 1)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
    "        \n",
    "        if i%display_freq == display_freq-1:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            print('Iteration', i, 'Loss', loss_arr[i])\n",
    "            plt.figure()\n",
    "            plt.plot(loss_arr[1:i], '-*')\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.show()\n",
    "            print('\\n\\n')\n",
    "            \n",
    "    torch.save(net, 'model.pt')\n",
    "    return loss_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TZY6RvqLtdX8"
   },
   "source": [
    "### Training without Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1oQ3ZIWvtjfN"
   },
   "outputs": [],
   "source": [
    "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "colab_type": "code",
    "id": "E6LjVKQfoVMU",
    "outputId": "9b3f7f5a-b98b-4203-d137-1780ee362fd8"
   },
   "outputs": [],
   "source": [
    "train_setup(net, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GM1Tj20omMi1"
   },
   "source": [
    "### Training with Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxFLBqW1Ip4v"
   },
   "outputs": [],
   "source": [
    "net_att = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "colab_type": "code",
    "id": "tdRpJUXNIwuv",
    "outputId": "6e8ed733-4b95-4eae-ac09-be4f6a905d18"
   },
   "outputs": [],
   "source": [
    "loss_history = train_setup(net_att, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "05F1-FwX6YVZ"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3TWC7zhAn3z"
   },
   "outputs": [],
   "source": [
    "def test(net, word, device = 'cpu'):\n",
    "    net = net.eval().to(device)\n",
    "    outputs = infer(net, word, 30, device)\n",
    "    hindi_output = ''\n",
    "    for out in outputs:\n",
    "        val, indices = out.topk(1)\n",
    "        index = indices.tolist()[0][0]\n",
    "        if index == 0:\n",
    "            break\n",
    "        hindi_char = hindi_alphabets[index+1]\n",
    "        hindi_output += hindi_char\n",
    "    print(word + ' - ' + hindi_output)\n",
    "    return hindi_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bT8bibYl7CgX"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(net, device = 'cpu'):\n",
    "    net = net.eval().to(device)\n",
    "    predictions = []\n",
    "    accuracy = 0\n",
    "    for i in range(len(test_data)):\n",
    "        eng, hindi = test_data[i]\n",
    "        gt = gt_rep(hindi, hindi_alpha2index, device)\n",
    "        outputs = infer(net, eng, gt.shape[0], device)\n",
    "        correct = 0\n",
    "        for index, out in enumerate(outputs):\n",
    "            val, indices = out.topk(1)\n",
    "            hindi_pos = indices.tolist()[0]\n",
    "            if hindi_pos[0] == gt[index][0]:\n",
    "                correct += 1\n",
    "        \n",
    "        accuracy += correct/gt.shape[0]\n",
    "    accuracy /= len(test_data)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "dy1bQiORAs5o",
    "outputId": "183c661a-56c9-4f31-a894-188207c58104"
   },
   "outputs": [],
   "source": [
    "accuracy = calc_accuracy(net) * 100\n",
    "accuracy_attn = calc_accuracy(net_att) * 100\n",
    "print('Accuracy w/o attention ', accuracy)\n",
    "print('Acurracy with attention', accuracy_attn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ukoNAs8wP-GH"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. Train longer and check accuracy - play with different hyperparameters\n",
    "2. Visualise attention - which part of the encoder output are we attending to\n",
    "3. Improve performance with batching - use the packing idea from earlier\n",
    "4. Try other attention mechanisms\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "0721_EncoderDecoderArchitecture.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
